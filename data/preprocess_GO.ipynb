{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import obonet\n",
    "import networkx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_inverse_edge = True\n",
    "\n",
    "reserved_edges = [\"is_a\"]\n",
    "inverse_edges = {\n",
    "    \"is_a\": \"is_a_inverse\",\n",
    "}\n",
    "e2i = {\"is_a\": 0, \"is_a_inverse\": 1}\n",
    "i2e = {0: \"is_a\", 1: \"is_a_inverse\"}\n",
    "\n",
    "out_dir = \"./processed/gograph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: read GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Some Go terms have alt_ids\n",
    "obo_basic_fp = \"./raw/go/go-basic.obo\"\n",
    "go_graph = obonet.read_obo(obo_basic_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pre-Process GO network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43558 nodes, 85713 edges exists in the GO graph.\n",
      "70058 edges are reserved in the GO graph.\n"
     ]
    }
   ],
   "source": [
    "# Delete edges including \"regulates\" \"part-of\"\n",
    "print(f\"{go_graph.number_of_nodes()} nodes, {go_graph.number_of_edges()} edges exists in the GO graph.\")\n",
    "droped_edge = []\n",
    "for u, v, e in go_graph.edges(keys=True):\n",
    "    if e not in reserved_edges:\n",
    "        droped_edge.append((u, v, e))\n",
    "for u, v, e in droped_edge:\n",
    "    go_graph.remove_edge(u, v, key=e)\n",
    "print(f\"{go_graph.number_of_edges()} edges are reserved in the GO graph.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get coarse grained of all nodes\"\"\"\n",
    "coarse_grained_nodes = {}\n",
    "\n",
    "def dp_cgnodes(node, graph):\n",
    "    if node in coarse_grained_nodes:\n",
    "        return\n",
    "    cg_nodes = set()\n",
    "    for u, v, e in graph.out_edges(node, keys=True):\n",
    "        assert e in reserved_edges\n",
    "        cg_nodes.add(v)\n",
    "        dp_cgnodes(v, graph)\n",
    "        cg_nodes = cg_nodes | coarse_grained_nodes[v]\n",
    "    coarse_grained_nodes[node] = cg_nodes\n",
    "\n",
    "for node in go_graph.nodes():\n",
    "    dp_cgnodes(node, go_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO graph: 43558 nodes, 140116 edges\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Add inverse edges\"\"\"\n",
    "def add_inverse_edges(graph):\n",
    "    additional_edges = []\n",
    "    for u, v, e in graph.edges(keys=True):\n",
    "        if \"inverse\" not in e and not graph.has_edge(v, u, key=inverse_edges[e]):\n",
    "            additional_edges.append((v, u, inverse_edges[e]))\n",
    "\n",
    "    for u, v, e in additional_edges:\n",
    "        graph.add_edge(u, v, key=e)\n",
    "\n",
    "if add_inverse_edge:\n",
    "    add_inverse_edges(go_graph)\n",
    "\n",
    "print(f\"GO graph: {go_graph.number_of_nodes()} nodes, {go_graph.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP graph: 28140 nodes, 102828 edges\n",
      "MF graph: 11238 nodes, 27516 edges\n",
      "CC graph: 4180 nodes, 9772 edges\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Separate the GO graph into three sub graphs\"\"\"\n",
    "bp_component = []\n",
    "mf_component = []\n",
    "cc_component = []\n",
    "\n",
    "for node, key in go_graph.nodes(data=True):\n",
    "    if key['namespace'] == 'biological_process':\n",
    "        bp_component.append(node)\n",
    "    elif key['namespace'] == 'molecular_function':\n",
    "        mf_component.append(node)\n",
    "    elif key['namespace'] == 'cellular_component':\n",
    "        cc_component.append(node)\n",
    "    else:\n",
    "        raise ValueError(f'Namespace \"{key[\"namespace\"]}\" is invalid of node {node}')\n",
    "\n",
    "# to unfreeze graph\n",
    "bp_graph = networkx.MultiDiGraph(go_graph.subgraph(bp_component))\n",
    "mf_graph = networkx.MultiDiGraph(go_graph.subgraph(mf_component))\n",
    "cc_graph = networkx.MultiDiGraph(go_graph.subgraph(cc_component))\n",
    "\n",
    "# print(f\"GO graph: {go_graph.number_of_nodes()} nodes, {go_graph.number_of_edges()} edges\")\n",
    "print(f\"BP graph: {bp_graph.number_of_nodes()} nodes, {bp_graph.number_of_edges()} edges\")\n",
    "print(f\"MF graph: {mf_graph.number_of_nodes()} nodes, {mf_graph.number_of_edges()} edges\")\n",
    "print(f\"CC graph: {cc_graph.number_of_nodes()} nodes, {cc_graph.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assign digital id to all nodes\"\"\"\n",
    "def bfs(graph):\n",
    "    # find root node\n",
    "    root = list(graph.nodes())[0]\n",
    "    while True:\n",
    "        out_edges = list(graph.out_edges(root, keys=True))\n",
    "        out_edges = [e for e in out_edges if \"inverse\" not in e[2]]\n",
    "        if len(out_edges) == 0:\n",
    "            break\n",
    "        root = out_edges[0][1]\n",
    "\n",
    "    idx = 0\n",
    "    queue = [root]\n",
    "    graph.nodes[root]['depth'] = 0\n",
    "\n",
    "    while len(queue) != 0:\n",
    "        cur_node = queue[0]\n",
    "        graph.nodes[cur_node][\"index\"] = idx\n",
    "\n",
    "        queue = queue[1:]\n",
    "        idx += 1\n",
    "        assert idx <= graph.number_of_nodes()\n",
    "\n",
    "        in_edges = list(graph.in_edges(cur_node, keys=True))\n",
    "        in_edges = [e for e in in_edges if \"inverse\" not in e[2]]\n",
    "\n",
    "        for u, v, k in in_edges:\n",
    "            if u in queue or graph.nodes[u].get(\"index\", None) is not None:\n",
    "                continue\n",
    "            queue.append(u)\n",
    "            graph.nodes[u]['depth'] = graph.nodes[v]['depth'] + 1\n",
    "\n",
    "bfs(bp_graph)\n",
    "bfs(mf_graph)\n",
    "bfs(cc_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get index of all nodes\"\"\"\n",
    "\n",
    "def get_node_index(graph):\n",
    "    node_to_idx = {n: k[\"index\"] for n, k in graph.nodes(data=True)}  \n",
    "    idx_to_node = {k[\"index\"]: n for n, k in graph.nodes(data=True)}  \n",
    "    idx_to_dep = {k['index']: k['depth'] for n, k in graph.nodes(data=True)}\n",
    "    return node_to_idx, idx_to_node, idx_to_dep\n",
    "\n",
    "bp_n2i, bp_i2n, bp_i2d = get_node_index(bp_graph)\n",
    "mf_n2i, mf_i2n, mf_i2d = get_node_index(mf_graph)\n",
    "cc_n2i, cc_i2n, cc_i2d = get_node_index(cc_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Turn ancestor into index\"\"\"\n",
    "\n",
    "def get_ancestors(nodes, n2i):\n",
    "    ancestors = {}\n",
    "    for n in nodes:\n",
    "        ancestors[n2i[n]] = sorted([n2i[n] for n in coarse_grained_nodes[n]])\n",
    "    return ancestors\n",
    "\n",
    "bp_ancestors = get_ancestors(bp_graph.nodes(), bp_n2i)\n",
    "mf_ancestors = get_ancestors(mf_graph.nodes(), mf_n2i)\n",
    "cc_ancestors = get_ancestors(cc_graph.nodes(), cc_n2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the adjacent edges of four graphs\"\"\"\n",
    "def get_adj(graph, n2i):\n",
    "    adj = []\n",
    "    for u, v, e in graph.edges(keys=True):\n",
    "        adj.append((n2i[u], e2i[e], n2i[v]))\n",
    "    return adj\n",
    "\n",
    "bp_adj = get_adj(bp_graph, bp_n2i)\n",
    "mf_adj = get_adj(mf_graph, mf_n2i)\n",
    "cc_adj = get_adj(cc_graph, cc_n2i)\n",
    "# go_adj = get_adj(go_graph, go_n2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get descriptions of all nodes\"\"\"\n",
    "import re\n",
    "p = re.compile('(\\[.+\\])|\\\"')\n",
    "\n",
    "def get_desc(graph, n2i):\n",
    "    node_descs = {}\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        desc = re.sub(p, \"\", data['def']).strip()\n",
    "        node_descs[n2i[node]] = desc\n",
    "    return node_descs\n",
    "\n",
    "bp_desc = get_desc(bp_graph, bp_n2i)\n",
    "mf_desc = get_desc(mf_graph, mf_n2i)\n",
    "cc_desc = get_desc(cc_graph, cc_n2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get leaf terms\"\"\"\n",
    "def get_leaf(graph, n2i):\n",
    "    leaves = []\n",
    "    for node in graph.nodes():\n",
    "        out_edges = list(graph.out_edges(node, keys=True))\n",
    "        out_edges = [e for e in out_edges if \"inverse\" in e[2]]\n",
    "        if len(out_edges) == 0:\n",
    "            leaves.append((node, n2i[node]))\n",
    "    return sorted(leaves, key=lambda x: x[1])\n",
    "\n",
    "bp_leaves = get_leaf(bp_graph, bp_n2i)\n",
    "mf_leaves = get_leaf(mf_graph, mf_n2i)\n",
    "cc_leaves = get_leaf(cc_graph, cc_n2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Get alts id of GO Terms\"\"\"\n",
    "# def get_alts(nodes, graph):\n",
    "#     for idx, node in enumerate(nodes):\n",
    "#         goid = node[2]\n",
    "#         alt_ids = graph.nodes[goid].get(\"alt_id\", [])\n",
    "#         node.append(\" \".join(alt_ids))\n",
    "\n",
    "# get_alts(bp_nodes, bp_graph)\n",
    "# get_alts(mf_nodes, mf_graph)\n",
    "# get_alts(cc_nodes, cc_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store Go graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networkx.write_gpickle(go_graph, os.path.join(out_dir, \"go.nx\"))\n",
    "\n",
    "def write_file(fp, lines, header=None):\n",
    "    with open(fp, \"w\") as f:\n",
    "        if header is not None:\n",
    "            f.write(header)\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "if add_inverse_edge:\n",
    "    # store e2i\n",
    "    with open(os.path.join(out_dir, \"edge_index.tsv\"), \"w\") as f:\n",
    "        f.write(\"Edge\\tIndex\\n\")\n",
    "        f.writelines([f\"{e}\\t{i}\\n\" for e, i in e2i.items()])\n",
    "\n",
    "\n",
    "def store(_dir, graph, n2i, i2n, i2d, leaves, ances, desc, adj):\n",
    "    os.makedirs(_dir, exist_ok=True)\n",
    "\n",
    "    networkx.write_gpickle(graph, os.path.join(_dir, \"graph.nx\"))\n",
    "\n",
    "    # store node2idx \n",
    "    write_file(\n",
    "        os.path.join(_dir, \"term_index.tsv\"),\n",
    "        [f\"{n}\\t{i}\\n\" for n, i in sorted([(n, i) for n, i in n2i.items()], key=lambda x: x[1])],\n",
    "        header=\"Term\\tIndex\\n\")\n",
    "\n",
    "    # store leaves\n",
    "    write_file(\n",
    "        os.path.join(_dir, 'term_leaf.tsv'),\n",
    "        [f\"{n}\\t{i}\\t{i2d[i]}\\n\" for n, i in leaves], header=\"Leaf\\tIndex\\tDepth\\n\")\n",
    "\n",
    "    # sotre term depth\n",
    "    write_file(\n",
    "        os.path.join(_dir, \"term_depth.tsv\"),\n",
    "        [f\"{i2n[i]}\\t{i}\\t{i2d[i]}\\n\" for i in range(len(i2d))],\n",
    "        header=\"Term\\tIndex\\tDepth\\n\")\n",
    "\n",
    "    # store father nodes\n",
    "    write_file(\n",
    "        os.path.join(_dir, \"term_ances.tsv\"),\n",
    "        [f\"{i2n[i]}\\t{i}\\t{' '.join(list(map(str, ances[i])))}\\n\" for i in range(len(ances))],\n",
    "        header=\"Term\\tIndex\\tAncestors\\n\")\n",
    "\n",
    "    # store node descriptions\n",
    "    write_file(\n",
    "        os.path.join(_dir, \"term_desc.tsv\"),\n",
    "        [f\"{i2n[i]}\\t{i}\\t{desc[i]}\\n\" for i in range(len(desc))],\n",
    "        header=\"Term\\tIndex\\tName\\n\")\n",
    "\n",
    "    # store adjacant matrix\n",
    "    write_file(\n",
    "        os.path.join(_dir, \"adj.tsv\"),\n",
    "        [f\"{i2n[si]}\\t{i2e[ei]}\\t{i2n[ti]}\\t{si}\\t{ei}\\t{ti}\\n\" for si, ei, ti in sorted(adj, key=lambda x: x[0])],\n",
    "        header=\"Souce\\tEdge\\tTarget\\tSIndex\\tEIndex\\tTIndex\\n\")\n",
    "\n",
    "store(os.path.join(out_dir, \"bp\"), bp_graph, bp_n2i, bp_i2n, bp_i2d, bp_leaves, bp_ancestors, bp_desc, bp_adj)\n",
    "store(os.path.join(out_dir, \"mf\"), mf_graph, mf_n2i, mf_i2n, mf_i2d, mf_leaves, mf_ancestors, mf_desc, mf_adj)\n",
    "store(os.path.join(out_dir, \"cc\"), cc_graph, cc_n2i, cc_i2n, cc_i2d, cc_leaves, cc_ancestors, cc_desc, cc_adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('workspace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d87a92dc5e820933ce1158afb1b057ba0389716ff9ef4f91230a9bbd9be5ff60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
