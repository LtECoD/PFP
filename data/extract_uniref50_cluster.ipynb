{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from lxml.etree import XMLSyntaxError\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "compressed_uniref50_xml = \"./data/raw/uniref50/uniref50.xml.gz\"\n",
    "\n",
    "# ncbi taxonomy\n",
    "# arabidopsisï¼š 3702\n",
    "# fly: 7227\n",
    "# mouse: 10090\n",
    "# worm: 6239\n",
    "# yeast: 559292\n",
    "# human: 9606\n",
    "target_taxons = [\"3702\", \"7227\", \"10090\", \"6239\", \"559292\", \"9606\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read xml.gz in a lazy way\n",
    "def each_chunk(stream, separator):\n",
    "    \"\"\"\n",
    "    Yield lines from `stream` until `separator`. Source: https://stackoverflow.com/a/47927374\n",
    "    \"\"\"\n",
    "    buffer = \"\"\n",
    "    while True:  # until EOF\n",
    "        chunk = stream.read(65536).decode()  # read 2^16 bytes\n",
    "        if not chunk:  # EOF?\n",
    "            yield buffer\n",
    "            break\n",
    "        buffer += chunk\n",
    "        while True:  # until no separator is found\n",
    "            try:\n",
    "                part, buffer = buffer.split(separator, 1)\n",
    "            except ValueError:\n",
    "                break\n",
    "            else:\n",
    "                yield part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"UniRef50\"  # to remove the label in the end of document\n",
    "\n",
    "# handle a entry\n",
    "def handle_entry(xml):\n",
    "    # -- parse the XML\n",
    "    xml = xml.replace(\"</{}>\\n\".format(label), \"\")\n",
    "    try:\n",
    "        root = etree.fromstring(xml)\n",
    "    except XMLSyntaxError:\n",
    "        print(xml)\n",
    "        return None\n",
    "\n",
    "    clusterid = root.get(\"id\")\n",
    "    protname = root.xpath(\"/entry/name/text()\")[0]\n",
    "    mem_string_list = []\n",
    "\n",
    "    # mem_cnt = int(root.xpath(\"/entry/property[@type='member count']/@value\")[0])\n",
    "    common_taxon = root.xpath(\"/entry/property[@type='common taxon']/@value\")[0]\n",
    "    common_taxon_id = root.xpath(\"/entry/property[@type='common taxon ID']/@value\")[0]\n",
    "   \n",
    "    # representative member\n",
    "    rep_mem_accessions = root.xpath(\"/entry/representativeMember/dbReference/property[@type='UniProtKB accession']/@value\")\n",
    "    rep_ncbi_taxon = root.xpath(\"/entry/representativeMember/dbReference/property[@type='NCBI taxonomy']/@value\")\n",
    "    assert len(rep_ncbi_taxon) == 1\n",
    "    if rep_ncbi_taxon[0] in target_taxons:\n",
    "        mem_string_list.append(\",\".join(rep_mem_accessions) + \":\" + rep_ncbi_taxon[0])\n",
    "\n",
    "    # members\n",
    "    members_entries = root.xpath(\"/entry/member/dbReference[@type='UniProtKB ID']\")\n",
    "    for mem in members_entries:\n",
    "        mem_accessions = mem.xpath(\"property[@type='UniProtKB accession']/@value\")\n",
    "        mem_ncbi_taxon = mem.xpath(\"property[@type='NCBI taxonomy']/@value\")\n",
    "        assert len(mem_ncbi_taxon) == 1\n",
    "        if mem_ncbi_taxon[0] in target_taxons:\n",
    "            mem_string_list.append(\",\".join(mem_accessions) + \":\" + mem_ncbi_taxon[0])\n",
    "\n",
    "    if len(mem_string_list) == 0:\n",
    "        return None\n",
    "\n",
    "    member_string = \";\".join(mem_string_list)\n",
    "    return f\"{clusterid}\\t{protname}\\t{common_taxon}\\t{common_taxon_id}\\t{member_string}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52523203it [4:25:57, 3291.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<entry id=\"UniRef50_UPI001BB8EC77\" updated=\"2022-04-27\">\n",
      "<name>Cluster: Uncharacterized protein</name>\n",
      "<property type=\"member count\" value=\"1\"/>\n",
      "<property type=\"common taxon\" value=\"Thermobacillus xylanilyticus\"/>\n",
      "<property type=\"common taxon ID\" value=\"76633\"/>\n",
      "<representativeMember>\n",
      "<dbReference type=\"UniParc ID\" id=\"UPI001BB8EC77\">\n",
      "<property type=\"UniRef100 ID\" value=\"UniRef100_UPI001BB8EC77\"/>\n",
      "<property type=\"UniRef90 ID\" value=\"UniRef90_UPI001BB8EC77\"/>\n",
      "<property type=\"protein name\" value=\"Uncharacterized protein\"/>\n",
      "<property type=\"source organism\" value=\"Szabonella\"/>\n",
      "<property type=\"NCBI taxonomy\" value=\"76633\"/>\n",
      "<property type=\"length\" value=\"11\"/>\n",
      "<property type=\"isSeed\" value=\"true\"/>\n",
      "</dbReference>\n",
      "<sequence length=\"11\" checksum=\"40EAC3F95AAEB9C7\">MVLLFCDIVRV</sequence>\n",
      "</representativeMember>\n",
      "</entry>\n",
      "</UniRef50>\n",
      "\n",
      "52523202 entries converted in 15957.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_f = gzip.open(\"./cluster_member_six_module_orgas.tsv.gz\", \"wb\")\n",
    "out_f.write(\"Entry\\tName\\tCommon Taxon\\tCommon Taxon ID\\tMembers\\n\".encode())\n",
    "out_f.flush()\n",
    "\n",
    "start = time()\n",
    "sep = \"<entry\"\n",
    "in_f = gzip.open(compressed_uniref50_xml, \"rb\")\n",
    "buffer_size = 1000\n",
    "buffer = []\n",
    "\n",
    "for idx, chunk in tqdm(enumerate(each_chunk(in_f, separator=sep)), mininterval=10):\n",
    "    if idx == 0:        # skip the header\n",
    "        continue\n",
    "\n",
    "    # -- get the XML entry as text\n",
    "    xml = sep + chunk  # separator has been dropped, add it to get a valid xml    \n",
    "\n",
    "    cluster = handle_entry(xml)\n",
    "    if cluster is not None:\n",
    "        buffer.append(cluster)\n",
    "    \n",
    "        if len(buffer) >= buffer_size:\n",
    "            out_f.write((\"\\n\".join(buffer)+\"\\n\").encode())\n",
    "            buffer = []\n",
    "            out_f.flush()\n",
    "\n",
    "if len(buffer) > 0:\n",
    "    out_f.write((\"\\n\".join(buffer)+\"\\n\").encode())\n",
    "    out_f.flush()\n",
    "    buffer = []\n",
    "\n",
    "end = time()\n",
    "in_f.close()\n",
    "out_f.close()\n",
    "print(\"{} entries converted in {:.2f} seconds\".format(idx, end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('workspace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d87a92dc5e820933ce1158afb1b057ba0389716ff9ef4f91230a9bbd9be5ff60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
